services:
  neo4j:
    image: neo4j:5-community
    container_name: neuronode-neo4j
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_server_memory_pagecache_size=512M
      - NEO4J_server_memory_heap_max__size=512M
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
    networks:
      - ki-network
    healthcheck:
      test: ["CMD", "neo4j", "status"]
      interval: 30s
      timeout: 10s
      retries: 5

  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: neuronode-chromadb
    ports:
      - "8000:8000"
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=FALSE
    volumes:
      - chroma_data:/chroma/chroma
    networks:
      - ki-network
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8000/api/v2/heartbeat"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 5

  redis:
    image: redis:7-alpine
    container_name: neuronode-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - ki-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  api:
    build: .
    container_name: neuronode-api
    ports:
      - "8080:8080"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    networks:
      - ki-network
    depends_on:
      neo4j:
        condition: service_healthy
      chromadb:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    container_name: neuronode-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    networks:
      - ki-network
    depends_on:
      - api

  # Backend Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8001:8080"
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - REDIS_HOST=redis
      - LITELLM_PROXY_URL=http://litellm-proxy:4000
    depends_on:
      - neo4j
      - chromadb
      - redis
      - litellm-proxy
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./src:/app/src
    networks:
      - ki-network

  # ===================================================================
  # LITELLM PROXY - ENTERPRISE CENTRAL LLM HUB
  # Version: v1.72.6-stable (Pre-Release with Performance Optimizations)
  # Features: aiohttp transport, multi-instance rate limiting, file permissions
  # ===================================================================
  litellm-proxy:
    image: ghcr.io/berriai/litellm:main-v1.72.6.rc
    container_name: neuronode-litellm-proxy
    ports:
      - "4000:4000"    # Main LiteLLM API endpoint
      - "4001:4001"    # Prometheus metrics endpoint
    environment:
      # ===== API KEYS =====
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      
      # ===== PERFORMANCE OPTIMIZATIONS (v1.72.0+) =====
      - USE_AIOHTTP_TRANSPORT=true           # 2x RPS improvement
      - EXPERIMENTAL_ENABLE_MULTI_INSTANCE_RATE_LIMITING=true
      
      # ===== DATABASE & STORAGE =====
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/litellm_db
      - STORE_MODEL_IN_DB=true
      
      # ===== REDIS CONFIGURATION =====
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      
      # ===== SECURITY & FEATURES =====
      - ENABLE_FILE_PERMISSIONS=true         # v1.72.0+ vector store control
      - ENABLE_AUDIT_LOGS=true              # Enterprise audit logging
      
      # ===== MONITORING & LOGGING =====
      - LITELLM_LOG=INFO
      - PROMETHEUS_PORT=4001
      - TRACK_END_USERS_PROMETHEUS=false    # Prevent metrics bloat
      
      # ===== MASTER KEY (LOADED FROM ENVIRONMENT) =====
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY:-sk-ki-system-master-2025}
      
      # ===== UI AUTHENTICATION (per Documentation) =====
      - UI_USERNAME=admin
      - UI_PASSWORD=${UI_PASSWORD:-litellm-enterprise-admin-2025}
      
      # ===== PRODUCTION SECURITY CONFIGURATION =====
      - DISABLE_AUTH=false                   # ✅ PRODUCTION SECURITY ENABLED
      - LITELLM_SALT_KEY=${LITELLM_SALT_KEY:-sk-salt-ki-system-secure-2025}
      - LITELLM_MODE=PRODUCTION               # Disables load_dotenv for security
    volumes:
      - ./litellm_config.yaml:/app/config.yaml:ro
      - litellm_logs:/app/logs
    command: [
      "--config", "/app/config.yaml",
      "--port", "4000",
      "--host", "0.0.0.0",
      "--detailed_debug"
    ]
    networks:
      - ki-network
    depends_on:
      - redis
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ===================================================================
  # LITELLM WEB UI - INTEGRATED IN PROXY (per Documentation)
  # UI läuft auf http://localhost:4000/ui (kein separater Container nötig)
  # Konfiguration: UI_USERNAME und UI_PASSWORD im litellm-proxy service
  # ===================================================================

  # ===================================================================
  # POSTGRESQL DATABASE FOR LITELLM
  # Required for: model storage, audit logs, rate limiting, budgets
  # ===================================================================
  postgres:
    image: postgres:15-alpine
    container_name: neuronode-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=litellm_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ki-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d litellm_db"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

networks:
  ki-network:
    driver: bridge

volumes:
  neo4j_data:
  neo4j_logs:
  neo4j_import:
  neo4j_plugins:
  chroma_data:
  redis_data:
  postgres_data:      # PostgreSQL data for LiteLLM
  litellm_logs:       # LiteLLM application logs