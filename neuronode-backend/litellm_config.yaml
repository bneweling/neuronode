general_settings:
  alerting:
  - slack
  allow_requests_on_db_unavailable: true
  database_connection_pool_limit: 10
  database_url: os.environ/DATABASE_URL
  disable_error_logs: true
  disable_router_logs: false
  disable_spend_logs: false
  enable_file_permissions: true
  experimental_enable_multi_instance_rate_limiting: true
  master_key: os.environ/LITELLM_MASTER_KEY
  prometheus_port: 4001
  proxy_batch_write_at: 60
  redis_host: redis
  redis_password: null
  redis_port: 6379
  store_model_in_db: true
  track_end_users_prometheus: false
  use_aiohttp_transport: true
litellm_settings:
  cache: true
  cache_params:
    host: redis
    password: null
    port: 6379
    type: redis
  json_logs: true
  request_timeout: 600
  set_verbose: false
model_list:
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 2048
    model: openai/gpt-4o
    temperature: 0.1
  model_info:
    cost_per_token: 5.0e-06
    mode: chat
    rpm: 500
    supports_function_calling: true
    tpm: 800000
  model_name: classification_premium
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 2048
    model: gemini/gemini-1.5-pro-latest
    temperature: 0.1
  model_info:
    cost_per_token: 3.5e-06
    mode: chat
    rpm: 300
    supports_function_calling: true
    tpm: 300000
  model_name: classification_balanced
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 2048
    model: gemini/gemini-1.5-flash-latest
    temperature: 0.1
  model_info:
    cost_per_token: 2.0e-07
    mode: chat
    rpm: 1000
    supports_function_calling: true
    tpm: 1000000
  model_name: classification_cost_effective
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 2048
    model: anthropic/claude-3-haiku-20240307
    temperature: 0.1
  model_info:
    cost_per_token: 2.5e-07
    mode: chat
    rpm: 400
    supports_function_calling: true
    tpm: 400000
  model_name: classification_specialized
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 2048
    model: openai/gpt-4o-mini
    temperature: 0.1
  model_info:
    cost_per_token: 1.5e-07
    mode: chat
    rpm: 500
    supports_function_calling: true
    tpm: 200000
  model_name: classification_ultra_fast
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 4096
    model: openai/gpt-4o
    temperature: 0.2
  model_info:
    cost_per_token: 5.0e-06
    mode: chat
    rpm: 500
    supports_function_calling: true
    supports_json_schema: true
    tpm: 800000
  model_name: extraction_premium
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 4096
    model: gemini/gemini-1.5-pro-latest
    temperature: 0.2
  model_info:
    cost_per_token: 3.5e-06
    mode: chat
    rpm: 300
    supports_function_calling: true
    supports_json_schema: true
    tpm: 300000
  model_name: extraction_balanced
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 4096
    model: gemini/gemini-1.5-flash-latest
    temperature: 0.2
  model_info:
    cost_per_token: 2.0e-07
    mode: chat
    rpm: 1000
    supports_function_calling: true
    tpm: 1000000
  model_name: extraction_cost_effective
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 4096
    model: anthropic/claude-3-5-sonnet-20241022
    temperature: 0.2
  model_info:
    cost_per_token: 3.0e-06
    mode: chat
    rpm: 400
    supports_function_calling: true
    tpm: 400000
  model_name: extraction_specialized
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 4096
    model: openai/gpt-4o-mini
    temperature: 0.2
  model_info:
    cost_per_token: 1.5e-07
    mode: chat
    rpm: 500
    supports_function_calling: true
    tpm: 200000
  model_name: extraction_ultra_fast
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 8192
    model: openai/gpt-4o
    temperature: 0.7
  model_info:
    cost_per_token: 5.0e-06
    mode: chat
    rpm: 500
    supports_function_calling: true
    supports_streaming: true
    tpm: 800000
  model_name: synthesis_premium
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 8192
    model: anthropic/claude-3-5-sonnet-20241022
    temperature: 0.7
  model_info:
    cost_per_token: 3.0e-06
    mode: chat
    rpm: 400
    supports_function_calling: true
    supports_streaming: true
    tpm: 400000
  model_name: synthesis_balanced
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 8192
    model: gemini/gemini-1.5-flash-latest
    temperature: 0.7
  model_info:
    cost_per_token: 2.0e-07
    mode: chat
    rpm: 1000
    supports_streaming: true
    tpm: 1000000
  model_name: synthesis_cost_effective
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 8192
    model: anthropic/claude-3-haiku-20240307
    temperature: 0.7
  model_info:
    cost_per_token: 2.5e-07
    mode: chat
    rpm: 400
    supports_streaming: true
    tpm: 400000
  model_name: synthesis_specialized
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 8192
    model: openai/gpt-4o-mini
    temperature: 0.7
  model_info:
    cost_per_token: 1.5e-07
    mode: chat
    rpm: 500
    supports_streaming: true
    tpm: 200000
  model_name: synthesis_ultra_fast
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 4096
    model: anthropic/claude-3-5-sonnet-20241022
    temperature: 0.1
  model_info:
    cost_per_token: 3.0e-06
    mode: chat
    rpm: 400
    supports_function_calling: true
    tpm: 400000
  model_name: validation_primary_premium
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 4096
    model: openai/gpt-4o
    temperature: 0.1
  model_info:
    cost_per_token: 5.0e-06
    mode: chat
    rpm: 500
    supports_function_calling: true
    tpm: 800000
  model_name: validation_primary_balanced
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 4096
    model: gemini/gemini-1.5-pro-latest
    temperature: 0.1
  model_info:
    cost_per_token: 3.5e-06
    mode: chat
    rpm: 300
    supports_function_calling: true
    tpm: 300000
  model_name: validation_primary_cost_effective
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 4096
    model: anthropic/claude-3-haiku-20240307
    temperature: 0.1
  model_info:
    cost_per_token: 2.5e-07
    mode: chat
    rpm: 400
    supports_function_calling: true
    tpm: 400000
  model_name: validation_primary_specialized
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 4096
    model: gemini/gemini-1.5-flash-latest
    temperature: 0.1
  model_info:
    cost_per_token: 2.0e-07
    mode: chat
    rpm: 1000
    supports_function_calling: true
    tpm: 1000000
  model_name: validation_primary_ultra_fast
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 4096
    model: openai/gpt-4o
    temperature: 0.1
  model_info:
    cost_per_token: 5.0e-06
    mode: chat
    rpm: 500
    supports_function_calling: true
    tpm: 800000
  model_name: validation_secondary_premium
- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    max_tokens: 4096
    model: gemini/gemini-1.5-pro-latest
    temperature: 0.1
  model_info:
    cost_per_token: 3.5e-06
    mode: chat
    rpm: 300
    supports_function_calling: true
    tpm: 300000
  model_name: validation_secondary_balanced
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 4096
    model: anthropic/claude-3-haiku-20240307
    temperature: 0.1
  model_info:
    cost_per_token: 2.5e-07
    mode: chat
    rpm: 400
    supports_function_calling: true
    tpm: 400000
  model_name: validation_secondary_cost_effective
- litellm_params:
    api_key: os.environ/ANTHROPIC_API_KEY
    max_tokens: 4096
    model: anthropic/claude-3-5-sonnet-20241022
    temperature: 0.1
  model_info:
    cost_per_token: 3.0e-06
    mode: chat
    rpm: 400
    supports_function_calling: true
    tpm: 400000
  model_name: validation_secondary_specialized
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    max_tokens: 4096
    model: openai/gpt-4o-mini
    temperature: 0.1
  model_info:
    cost_per_token: 1.5e-07
    mode: chat
    rpm: 500
    supports_function_calling: true
    tpm: 200000
  model_name: validation_secondary_ultra_fast

# ===================================================================
# EMBEDDING MODELS - ENTERPRISE EDITION
# Profile-based embedding model assignments for vector operations
# ===================================================================

- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    model: gemini/text-embedding-004
  model_info:
    cost_per_token: 1.3e-07
    mode: embedding
    input_cost_per_token: 1.3e-07
    output_vector_size: 768
    max_input_tokens: 2048
    rpm: 1500
    tpm: 1500000
  model_name: embeddings_premium

- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    model: openai/text-embedding-3-large
  model_info:
    cost_per_token: 1.3e-07
    mode: embedding
    input_cost_per_token: 1.3e-07
    output_vector_size: 3072
    max_input_tokens: 8191
    rpm: 5000
    tpm: 5000000
  model_name: embeddings_balanced

- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    model: openai/text-embedding-3-small
  model_info:
    cost_per_token: 2.0e-08
    mode: embedding
    input_cost_per_token: 2.0e-08
    output_vector_size: 1536
    max_input_tokens: 8191
    rpm: 5000
    tpm: 5000000
  model_name: embeddings_cost_effective

- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    model: gemini/text-embedding-004
  model_info:
    cost_per_token: 1.3e-07
    mode: embedding
    input_cost_per_token: 1.3e-07
    output_vector_size: 768
    max_input_tokens: 2048
    rpm: 1500
    tpm: 1500000
  model_name: embeddings_specialized

- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    model: openai/text-embedding-ada-002
  model_info:
    cost_per_token: 1.0e-07
    mode: embedding
    input_cost_per_token: 1.0e-07
    output_vector_size: 1536
    max_input_tokens: 8191
    rpm: 3000
    tpm: 1000000
  model_name: embeddings_ultra_fast

# ===================================================================
# EMBEDDING ALIASES - PROFILE SYSTEM INTEGRATION
# Map generic embedding requests to specific profile-based models
# ===================================================================

- litellm_params:
    api_key: os.environ/GEMINI_API_KEY
    model: gemini/text-embedding-004
  model_info:
    cost_per_token: 1.3e-07
    mode: embedding
    input_cost_per_token: 1.3e-07
    output_vector_size: 768
    max_input_tokens: 2048
    rpm: 1500
    tpm: 1500000
  model_name: embeddings  # Default embedding alias
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    model: openai/text-embedding-3-large
  model_info:
    cost_per_token: 1.3e-07
    mode: embedding
    rpm: 3000
    tpm: 1000000
  model_name: embeddings_primary
- litellm_params:
    api_key: os.environ/OPENAI_API_KEY
    model: openai/text-embedding-3-small
  model_info:
    cost_per_token: 2.0e-08
    mode: embedding
    rpm: 3000
    tpm: 1000000
  model_name: embeddings_fast
profile_settings:
  available_profiles:
    balanced:
      cost_level: medium
      description: Ausgewogene Performance und Kosten
      model_mappings:
        classification: classification_balanced
        extraction: extraction_balanced
        synthesis: synthesis_balanced
        validation_primary: validation_primary_balanced
        validation_secondary: validation_secondary_balanced
        embeddings: embeddings_balanced
      performance_level: high
    cost_effective:
      cost_level: low
      description: Budget-optimiert
      model_mappings:
        classification: classification_cost_effective
        extraction: extraction_cost_effective
        synthesis: synthesis_cost_effective
        validation_primary: validation_primary_cost_effective
        validation_secondary: validation_secondary_cost_effective
        embeddings: embeddings_cost_effective
      performance_level: good
    premium:
      cost_level: high
      description: Beste Modelle f√ºr Production
      model_mappings:
        classification: classification_premium
        extraction: extraction_premium
        synthesis: synthesis_premium
        validation_primary: validation_primary_premium
        validation_secondary: validation_secondary_premium
        embeddings: embeddings_premium
      performance_level: maximum
    specialized:
      cost_level: medium
      description: Spezialisierte Tasks
      model_mappings:
        classification: classification_specialized
        extraction: extraction_specialized
        synthesis: synthesis_specialized
        validation_primary: validation_primary_specialized
        validation_secondary: validation_secondary_specialized
        embeddings: embeddings_specialized
      performance_level: high
    ultra_fast:
      cost_level: low
      description: Maximale Geschwindigkeit
      model_mappings:
        classification: classification_ultra_fast
        extraction: extraction_ultra_fast
        synthesis: synthesis_ultra_fast
        validation_primary: validation_primary_ultra_fast
        validation_secondary: validation_secondary_ultra_fast
        embeddings: embeddings_ultra_fast
      performance_level: good
  current_profile: specialized
  profile_switch_history:
  - from_profile: premium
    mappings_updated: 5
    timestamp: '2025-07-01T19:00:08.186286'
    to_profile: balanced
  - from_profile: balanced
    mappings_updated: 5
    timestamp: '2025-07-01T19:05:55.377899'
    to_profile: premium
  - from_profile: premium
    mappings_updated: 5
    timestamp: '2025-07-01T19:06:47.630445'
    to_profile: cost_effective
  - from_profile: cost_effective
    mappings_updated: 5
    timestamp: '2025-07-01T19:07:03.830217'
    to_profile: ultra_fast
  - from_profile: ultra_fast
    mappings_updated: 5
    timestamp: '2025-07-01T19:07:03.871944'
    to_profile: balanced
  - from_profile: balanced
    mappings_updated: 5
    timestamp: '2025-07-01T19:07:03.908929'
    to_profile: specialized
router_settings:
  cooldown_time: 30
  enable_file_based_routing: true
  enable_loadbalancing: true
  enable_pre_call_checks: true
  max_retries: 3
  model_group_alias:
    classification: classification_specialized
    extraction: extraction_specialized
    synthesis: synthesis_specialized
    validation_primary: validation_primary_specialized
    validation_secondary: validation_secondary_specialized
    embeddings: embeddings_specialized
  profile_management:
    api_endpoints:
      get_status: /admin/profiles/status
      list_profiles: /admin/profiles/list
      switch_profile: /admin/profiles/switch
      validate_assignments: /admin/profiles/validate
    enabled: true
    ui_integration: true
  redis_host: redis
  redis_password: null
  redis_port: 6379
  routing_strategy: simple-shuffle
  timeout: 30.0
